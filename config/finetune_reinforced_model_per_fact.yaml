model_family: llama3-8b
model_path: ft_model_checkpoint/ft_llama3_8b

unlearn_data_id: 0
data_path: synthetic_data/family_relationships.pt
subsample_path: synthetic_data/subsample.pt
batch_size: 1
gradient_accumulation_steps: 1
num_epochs: 10
lr_scheduler_type: linear
save_dir: /data/ruihan/llm_unlearning/checkpoint_whp_tv/reinforced_model/${model_family}/${unlearn_data_id}/

weight_decay: 0.01
seed: 42
